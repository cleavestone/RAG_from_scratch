# ðŸ“š Retrieval-Augmented Generation (RAG) Learning Journey

This repository documents my hands-on learning path in **Retrieval-Augmented Generation (RAG)**.  
The goal is to build a strong foundation, explore different components step by step, and eventually design scalable RAG systems for real-world use cases.  

---

## âœ… Completed Notebooks

### 1. Mathematical Foundations of RAG
- Understanding the **core math** behind retrieval and generation.  
- Probability basics, similarity metrics, and vector space concepts.  
- Provides the groundwork for later modules on embeddings and retrieval.  

### 2. Text Chunking Strategies
- Explored why **chunking is critical** for RAG.  
- Implemented and compared multiple strategies:  
  - Fixed-size chunking  
  - Sentence-based chunking  
  - Semantic chunking  
  - Overlapping windows  
  - Structure-aware chunking  

### 3. Embedding Models  
- Learned about **Word embeddings, sentence embeddings, document embeddings, and multilingual embeddings**.  
- Hands-on with pre-trained models like `all-MiniLM-L6-v2` (SBERT).  
- Implemented **cosine similarity** to compare embeddings.  
- Covered **fine-tuning embeddings** for domain-specific tasks.  
