{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98bedc82",
   "metadata": {},
   "source": [
    "### Linear ALgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f56a97",
   "metadata": {},
   "source": [
    "#### Vectors - The Building Blocks of Embeddings\n",
    "\n",
    "#### What is a Vector?\n",
    "A vector is a mathematical object that has both magnitude (length) and direction. In RAG systems, vectors represent text embeddings - numerical representations of words, sentences, or documents.\n",
    "Mathematical Definition:\n",
    "A vector v in n-dimensional space is written as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3a0fa4",
   "metadata": {},
   "source": [
    "v = [v₁, v₂, v₃, ..., vₙ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf10f6c6",
   "metadata": {},
   "source": [
    "#### Example in RAG Context:\n",
    "\n",
    "If we have a sentence **The cat sits on the mat**, it might be represented as a 384-dimensional vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e6e7083",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embedding = [0.23, -0.15, 0.67, 0.89, -0.34, ..., 0.12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2128ee71",
   "metadata": {},
   "source": [
    "#### Vector Properties\n",
    "\n",
    "**Magnitude (Length) of a Vector**:\n",
    "The magnitude of a vector v is calculated using the Euclidean norm:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c7817d",
   "metadata": {},
   "source": [
    "||v|| = √(v₁² + v₂² + v₃² + ... + vₙ²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "115e8fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector magnitude: 0.9950\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Example embedding vector\n",
    "embedding = np.array([0.5, -0.3, 0.8, 0.1])\n",
    "magnitude = np.linalg.norm(embedding)\n",
    "print(f\"Vector magnitude: {magnitude:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49562a18",
   "metadata": {},
   "source": [
    "#### Unit Vectors (Normalized Vectors):\n",
    "\n",
    "A unit vector has a magnitude of 1. This is crucial in RAG systems for fair similarity comparisons:\n",
    "\n",
    "v̂ = v / ||v||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7273a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized vector: [ 0.50251891 -0.30151134  0.80403025  0.10050378]\n",
      "New magnitude: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Normalize the vector\n",
    "normalized_embedding = embedding / np.linalg.norm(embedding)\n",
    "print(f\"Normalized vector: {normalized_embedding}\")\n",
    "print(f\"New magnitude: {np.linalg.norm(normalized_embedding):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc9661",
   "metadata": {},
   "source": [
    "### Vector Operations\n",
    "\n",
    "**Vector Addition**:\n",
    "u + v = [u₁ + v₁, u₂ + v₂, ..., uₙ + vₙ]\n",
    "\n",
    "**Scalar Multiplication**:\n",
    "c × v = [c × v₁, c × v₂, ..., c × vₙ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1949428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined embedding: [ 0.37 -0.11  0.3 ]\n"
     ]
    }
   ],
   "source": [
    "# Combining embeddings from different sources\n",
    "query_embedding = np.array([0.4, -0.2, 0.6])\n",
    "context_embedding = np.array([0.3, 0.1, -0.4])\n",
    "\n",
    "# Weighted combination for enhanced retrieval\n",
    "combined = 0.7 * query_embedding + 0.3 * context_embedding\n",
    "print(f\"Combined embedding: {combined}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d236cc9b",
   "metadata": {},
   "source": [
    "### Matrices - Operations on Multiple Vectors\n",
    "\n",
    "**Matrix Basics**\n",
    "\n",
    "A matrix is a rectangular array of numbers. In RAG systems, matrices often represent collections of embeddings.\n",
    "Matrix Representation:\n",
    "\n",
    "A = ```[a₁₁  a₁₂  a₁₃]\n",
    "       [a₂₁  a₂₂  a₂₃]\n",
    "       [a₃₁  a₃₂  a₃₃]\n",
    "       ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d753e82c",
   "metadata": {},
   "source": [
    "### Document-Term Matrix Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3249a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "# Each row is a document embedding, each column is a dimension\n",
    "document_embeddings = np.array([\n",
    "    [0.5, -0.3, 0.8],  # Document 1\n",
    "    [0.2,  0.7, -0.1], # Document 2\n",
    "    [-0.4, 0.1,  0.6]  # Document 3\n",
    "])\n",
    "print(f\"Shape: {document_embeddings.shape}\")  # (3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9605b66f",
   "metadata": {},
   "source": [
    "## Similarity Measures\n",
    "1.) **Dot Product - The Foundation of Similarity**\n",
    "\n",
    "**Mathematical Definition**\n",
    "The dot product of two vectors u and v is:\n",
    "\n",
    "### u · v = u₁v₁ + u₂v₂ + ... + uₙvₙ = Σ(i=1 to n) uᵢvᵢ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd0153",
   "metadata": {},
   "source": [
    "**Geometric Interpretation**\n",
    "\n",
    "### u · v = ||u|| × ||v|| × cos(θ)\n",
    "\n",
    "where θ is the angle between the vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a20750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy dot product: 0.8400\n",
      "Manual calculation: 0.8400\n"
     ]
    }
   ],
   "source": [
    "def dot_product(u, v):\n",
    "    \"\"\"Calculate dot product manually\"\"\"\n",
    "    return sum(u[i] * v[i] for i in range(len(u)))\n",
    "\n",
    "# Example vectors (sentence embeddings)\n",
    "sentence1 = np.array([0.5, -0.3, 0.8, 0.1])\n",
    "sentence2 = np.array([0.4, -0.2, 0.7, 0.2])\n",
    "\n",
    "# Calculate dot product\n",
    "dot_prod = np.dot(sentence1, sentence2)\n",
    "manual_dot = dot_product(sentence1, sentence2)\n",
    "\n",
    "print(f\"NumPy dot product: {dot_prod:.4f}\")\n",
    "print(f\"Manual calculation: {manual_dot:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f0ad8",
   "metadata": {},
   "source": [
    "### RAG Application - Document Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac6d8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document rankings (index, score):\n",
      "Document 0: 0.6800\n",
      "Document 2: -0.0200\n",
      "Document 1: -0.0600\n"
     ]
    }
   ],
   "source": [
    "def rank_documents_by_dot_product(query_embedding, document_embeddings):\n",
    "    \"\"\"Rank documents by dot product similarity\"\"\"\n",
    "    scores = []\n",
    "    for i, doc_emb in enumerate(document_embeddings):\n",
    "        score = np.dot(query_embedding, doc_emb)\n",
    "        scores.append((i, score))\n",
    "    \n",
    "    # Sort by score (descending)\n",
    "    return sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Example usage\n",
    "query = np.array([0.6, -0.2, 0.4])\n",
    "docs = np.array([\n",
    "    [0.5, -0.3, 0.8],\n",
    "    [0.2,  0.7, -0.1],\n",
    "    [-0.4, 0.1,  0.6]\n",
    "])\n",
    "\n",
    "rankings = rank_documents_by_dot_product(query, docs)\n",
    "print(\"Document rankings (index, score):\")\n",
    "for idx, score in rankings:\n",
    "    print(f\"Document {idx}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de95fc53",
   "metadata": {},
   "source": [
    "### Cosine Similarity - Angle-Based Similarity\n",
    "\n",
    "Cosine similarity measures the cosine of the angle between two vectors:\n",
    "### cos_sim(u, v) = (u · v) / (||u|| × ||v||)\n",
    "\n",
    "\n",
    "**Why Cosine Similarity**?\n",
    "\n",
    "- Magnitude Independent: Focuses on direction, not magnitude\n",
    "- Range: Always between -1 and 1\n",
    "- Interpretation: 1 = identical direction, 0 = orthogonal, -1 = opposite direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d9ccce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.9449\n",
      "Sklearn result: 0.9449\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
    "    dot_product = np.dot(u, v)\n",
    "    magnitude_u = np.linalg.norm(u)\n",
    "    magnitude_v = np.linalg.norm(v)\n",
    "    \n",
    "    if magnitude_u == 0 or magnitude_v == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    return dot_product / (magnitude_u * magnitude_v)\n",
    "\n",
    "# Example calculation\n",
    "sentence1 = np.array([3, -1, 2])\n",
    "sentence2 = np.array([1, 0, 1])\n",
    "\n",
    "cos_sim = cosine_similarity(sentence1, sentence2)\n",
    "print(f\"Cosine similarity: {cos_sim:.4f}\")\n",
    "\n",
    "# Using sklearn for verification\n",
    "from sklearn.metrics.pairwise import cosine_similarity as sklearn_cosine\n",
    "cos_sim_sklearn = sklearn_cosine([sentence1], [sentence2])[0][0]\n",
    "print(f\"Sklearn result: {cos_sim_sklearn:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849bdc1e",
   "metadata": {},
   "source": [
    "### Batch Cosine Similarity Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f18cf342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarities:\n",
      "Document 0: 0.9179\n",
      "Document 1: -0.1091\n",
      "Document 2: -0.0367\n",
      "Document 3: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def batch_cosine_similarity(query, documents):\n",
    "    \"\"\"Efficiently compute cosine similarity for multiple documents\"\"\"\n",
    "    # Normalize query\n",
    "    query_norm = query / np.linalg.norm(query)\n",
    "    \n",
    "    # Normalize documents\n",
    "    doc_norms = documents / np.linalg.norm(documents, axis=1, keepdims=True)\n",
    "    \n",
    "    # Compute similarities\n",
    "    similarities = np.dot(doc_norms, query_norm)\n",
    "    return similarities\n",
    "\n",
    "# Example with multiple documents\n",
    "query = np.array([0.6, -0.2, 0.4])\n",
    "docs = np.array([\n",
    "    [0.5, -0.3, 0.8],\n",
    "    [0.2,  0.7, -0.1],\n",
    "    [-0.4, 0.1,  0.6],\n",
    "    [0.6, -0.2, 0.4]  # Same as query\n",
    "])\n",
    "\n",
    "similarities = batch_cosine_similarity(query, docs)\n",
    "print(\"Cosine similarities:\")\n",
    "for i, sim in enumerate(similarities):\n",
    "    print(f\"Document {i}: {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e2eef1",
   "metadata": {},
   "source": [
    "### Euclidean Distance - Geometric Distance\n",
    "\n",
    "\n",
    "The Euclidean distance between two points (vectors) is:\n",
    "\n",
    "### d(u, v) = √[(u₁-v₁)² + (u₂-v₂)² + ... + (uₙ-vₙ)²]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "044a6e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual calculation: 7.0711\n",
      "NumPy calculation: 7.0711\n"
     ]
    }
   ],
   "source": [
    "def euclidean_distance(u, v):\n",
    "    \"\"\"Calculate Euclidean distance between two vectors\"\"\"\n",
    "    return np.sqrt(np.sum((u - v) ** 2))\n",
    "\n",
    "# Alternative using numpy\n",
    "def euclidean_distance_np(u, v):\n",
    "    return np.linalg.norm(u - v)\n",
    "\n",
    "# Example\n",
    "point1 = np.array([1, 2, 3])\n",
    "point2 = np.array([4, 6, 8])\n",
    "\n",
    "dist1 = euclidean_distance(point1, point2)\n",
    "dist2 = euclidean_distance_np(point1, point2)\n",
    "\n",
    "print(f\"Manual calculation: {dist1:.4f}\")\n",
    "print(f\"NumPy calculation: {dist2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463d2a0",
   "metadata": {},
   "source": [
    "### Manhattan Distance (L1 Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e1ae475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manhattan distance: 12\n"
     ]
    }
   ],
   "source": [
    "def manhattan_distance(u, v):\n",
    "    \"\"\"Calculate Manhattan distance\"\"\"\n",
    "    return np.sum(np.abs(u - v))\n",
    "\n",
    "# Example\n",
    "point1 = np.array([1, 2, 3])\n",
    "point2 = np.array([4, 6, 8])\n",
    "\n",
    "manhattan_dist = manhattan_distance(point1, point2)\n",
    "print(f\"Manhattan distance: {manhattan_dist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f46f39d",
   "metadata": {},
   "source": [
    "## Probability and Statistics Fundamentals\n",
    "\n",
    "**Probability Distributions**\n",
    "In RAG systems, we often work with probability distributions over vocabulary, documents, or similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ae70bf",
   "metadata": {},
   "source": [
    "### Softmax Function - Converting Scores to Probabilities\n",
    "The softmax function converts a vector of real numbers into a probability distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f437c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity scores: [2.5 1.8 3.2 0.9]\n",
      "Probabilities: [0.26937953 0.13376992 0.54246376 0.05438679]\n",
      "Sum of probabilities: 1.0\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax of vector x\"\"\"\n",
    "    # Subtract max for numerical stability\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "# Example: Converting similarity scores to probabilities\n",
    "similarity_scores = np.array([2.5, 1.8, 3.2, 0.9])\n",
    "probabilities = softmax(similarity_scores)\n",
    "\n",
    "print(\"Similarity scores:\", similarity_scores)\n",
    "print(\"Probabilities:\", probabilities)\n",
    "print(\"Sum of probabilities:\", np.sum(probabilities))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f2e50",
   "metadata": {},
   "source": [
    "### RAG Application - Document Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b633ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document selection probabilities:\n",
      "Document 0: 0.7834\n",
      "Document 1: 0.1005\n",
      "Document 2: 0.1161\n"
     ]
    }
   ],
   "source": [
    "def probabilistic_document_selection(query_embedding, doc_embeddings, temperature=1.0):\n",
    "    \"\"\"Select documents probabilistically based on similarity\"\"\"\n",
    "    # Compute similarities\n",
    "    similarities = []\n",
    "    for doc_emb in doc_embeddings:\n",
    "        sim = cosine_similarity(query_embedding, doc_emb)\n",
    "        similarities.append(sim)\n",
    "    \n",
    "    # Apply temperature scaling\n",
    "    scaled_scores = np.array(similarities) / temperature\n",
    "    \n",
    "    # Convert to probabilities\n",
    "    probs = softmax(scaled_scores)\n",
    "    \n",
    "    return probs\n",
    "\n",
    "# Example usage\n",
    "query = np.array([0.6, -0.2, 0.4])\n",
    "docs = np.array([\n",
    "    [0.5, -0.3, 0.8],\n",
    "    [0.2,  0.7, -0.1],\n",
    "    [-0.4, 0.1,  0.6]\n",
    "])\n",
    "\n",
    "probs = probabilistic_document_selection(query, docs, temperature=0.5)\n",
    "print(\"Document selection probabilities:\")\n",
    "for i, p in enumerate(probs):\n",
    "    print(f\"Document {i}: {p:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5befa16d",
   "metadata": {},
   "source": [
    "### Statistical Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4cbbdd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall mean: 0.0060\n",
      "Overall std: 0.9968\n",
      "Mean of first 5 dimensions: [-0.22433486 -0.27268405 -0.05164164  0.10443067 -0.02384187]\n"
     ]
    }
   ],
   "source": [
    "def embedding_statistics(embeddings):\n",
    "    \"\"\"Calculate statistics for a collection of embeddings\"\"\"\n",
    "    # Convert to numpy array if needed\n",
    "    embeddings = np.array(embeddings)\n",
    "    \n",
    "    # Calculate statistics along each dimension\n",
    "    means = np.mean(embeddings, axis=0)\n",
    "    variances = np.var(embeddings, axis=0)\n",
    "    std_devs = np.std(embeddings, axis=0)\n",
    "    \n",
    "    # Overall statistics\n",
    "    overall_mean = np.mean(embeddings)\n",
    "    overall_std = np.std(embeddings)\n",
    "    \n",
    "    return {\n",
    "        'dimension_means': means,\n",
    "        'dimension_variances': variances,\n",
    "        'dimension_std_devs': std_devs,\n",
    "        'overall_mean': overall_mean,\n",
    "        'overall_std': overall_std\n",
    "    }\n",
    "\n",
    "# Example with document embeddings\n",
    "doc_embeddings = np.random.randn(100, 384)  # 100 docs, 384-dim embeddings\n",
    "stats = embedding_statistics(doc_embeddings)\n",
    "\n",
    "print(f\"Overall mean: {stats['overall_mean']:.4f}\")\n",
    "print(f\"Overall std: {stats['overall_std']:.4f}\")\n",
    "print(f\"Mean of first 5 dimensions: {stats['dimension_means'][:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac1741d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
