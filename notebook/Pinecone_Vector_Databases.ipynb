{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fad9a5d",
   "metadata": {},
   "source": [
    "# ðŸ“Œ Pinecone Vector Database\n",
    "\n",
    "[Pinecone](https://www.pinecone.io/) is a **managed vector database** designed for storing, indexing, and querying high-dimensional vectors (embeddings).  \n",
    "Itâ€™s built for **semantic search, recommendation systems, and Retrieval-Augmented Generation (RAG)** at scale, removing the need to manage your own infrastructure.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ Why Pinecone?\n",
    "- **Fully managed & serverless** â†’ No need to handle clusters or scaling manually.  \n",
    "- **Fast similarity search** â†’ Uses optimized Approximate Nearest Neighbor (ANN) algorithms.  \n",
    "- **Scalable** â†’ Handles millions to billions of vectors efficiently.  \n",
    "- **Hybrid search** â†’ Supports filtering with metadata + vector similarity.  \n",
    "- **Integrations** â†’ Works smoothly with LangChain, Hugging Face, OpenAI, etc.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§© What I Did in This Notebook\n",
    "- Generated an API key and **initialized Pinecone**.  \n",
    "- Created an **index** (dimension = `384` from SentenceTransformer embeddings).  \n",
    "- Loaded and chunked my **resume PDF** using LangChain utilities.  \n",
    "- Converted chunks into embeddings using **Sentence Transformers**.  \n",
    "- **Upserted** embeddings and metadata into Pinecone.  \n",
    "- Queried Pinecone to **retrieve the most relevant text chunks**.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”‘ Key Concepts\n",
    "- **Index** â†’ A logical collection of vectors (similar to a table in SQL).  \n",
    "- **Namespace** â†’ Partition within an index (helps organize data).  \n",
    "- **Upsert** â†’ Insert or update vectors in the index.  \n",
    "- **Query** â†’ Find the most similar vectors to a given embedding.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“– Next Steps\n",
    "- Experiment with other vector databases (FAISS, Weaviate, ChromaDB).  \n",
    "- Try hybrid search (combine **metadata filtering** + vector search).  \n",
    "- Build a **mini RAG pipeline** that retrieves context from Pinecone and generates answers.  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1561c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4\n",
    "import pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0585e271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1c6288",
   "metadata": {},
   "source": [
    "## Initialize Pinecone and Create and Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a16da053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Pinecone index: cv-index\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "if api_key is None:\n",
    "    raise ValueError(\"Missing Pinecone API key. Did you set it in your .env?\")\n",
    "\n",
    "pc = Pinecone(api_key=api_key)\n",
    "\n",
    "index_name = \"cv-index\"\n",
    "\n",
    "# Create index if it doesn't exist\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,  # Match SentenceTransformer embedding size\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "    #pc.describe_index(index_name).wait_until_ready()\n",
    "\n",
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "print(f\"Connected to Pinecone index: {index_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5457efe5",
   "metadata": {},
   "source": [
    "**The dimension=384 is specific to the all-MiniLM-L6-v2 model. If you use a different Sentence Transformer model, check its embedding dimension.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711cd978",
   "metadata": {},
   "source": [
    "## Load and Chunk Your CV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe819d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 42\n",
      "Chunk 1: CLEAVESTONE ADUNGO \n",
      "cleavestone94@gmail.com   |   +254703457427   |   Nairobi Kenya       \n",
      "GitHub: L... [{'source': 'cv'}]\n",
      "Chunk 2: Summary      \n",
      "Data Scientist transitioning from finance with 2+ years of hands-on ML, NLP, and data ... [{'source': 'cv'}]\n"
     ]
    }
   ],
   "source": [
    "# Load the PDF CV\n",
    "pdf_path = \"data/resume.pdf\"\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "pages = loader.load()\n",
    "\n",
    "# Combine all pages into a single text\n",
    "cv_text = \"\".join(page.page_content for page in pages)\n",
    "\n",
    "# Create a Document object\n",
    "cv_document = Document(page_content=cv_text, metadata={\"source\": \"cv\"})\n",
    "\n",
    "# Chunk the document\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=200,  # Adjust chunk size as needed\n",
    "    chunk_overlap=50,  # Overlap to retain context\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents([cv_document])\n",
    "\n",
    "# Print the number of chunks and a sample\n",
    "print(f\"Number of chunks: {len(chunks)}\")\n",
    "for i, chunk in enumerate(chunks[:2]):  # Show first two chunks\n",
    "    print(f\"Chunk {i+1}: {chunk.page_content[:100]}... [{chunk.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef11edc5",
   "metadata": {},
   "source": [
    "- **PyPDFLoader** extracts text from your PDF CV.  \n",
    "- **RecursiveCharacterTextSplitter** splits the text into manageable chunks (e.g., `500` characters with `50`-character overlap).  \n",
    "- Each chunk is stored as a **Document** with metadata (e.g., `source: cv`).  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74301760",
   "metadata": {},
   "source": [
    "## Initialize Sentence Transformer for Embeddings\n",
    "\n",
    "The **all-MiniLM-L6-v2** model is lightweight and performs well for most tasks. You can explore other models on Hugging Face.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e23221b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentence Transformer model\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3eaa5d",
   "metadata": {},
   "source": [
    "## Embed and Store Chunks in Pinecone\n",
    "Embed the chunks using Sentence Transformers and store them in the Pinecone index.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c1fe0423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully stored 42 chunks in Pinecone index 'cv-index'\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "\n",
    "uuids = [str(uuid4()) for _ in range(len(chunks))]\n",
    "embeddings = [embedding_model.encode(chunk.page_content).tolist() for chunk in chunks]\n",
    "\n",
    "vectors = [\n",
    "    (\n",
    "        uuids[i],\n",
    "        embeddings[i],\n",
    "        {\n",
    "            \"text\": chunks[i].page_content,\n",
    "            **{k: str(v) for k, v in chunks[i].metadata.items()}  # flatten metadata\n",
    "        }\n",
    "    )\n",
    "    for i in range(len(chunks))\n",
    "]\n",
    "\n",
    "index.upsert(vectors=vectors)\n",
    "print(f\"Successfully stored {len(vectors)} chunks in Pinecone index '{index_name}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ca76ce",
   "metadata": {},
   "source": [
    "- Each chunk is **embedded** using the Sentence Transformer model, converting text into a **384-dimensional vector**.  \n",
    "- We generate **unique IDs** for each chunk using `uuid4`.  \n",
    "- The **upsert** method stores the embeddings and metadata in **Pinecone**.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f0ef75",
   "metadata": {},
   "source": [
    "## Query the Vector Store\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "372dfbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* [Score=0.585] data into actionable insights and delivering production-ready ML solutions. Competitive ML participa... [{'source': 'cv', 'text': 'data into actionable insights and delivering production-ready ML solutions. Competitive ML participant (top \\n30% Zindi), passionate about solving high-impact problems with data. \\nSkills      \\nProgramming & Analytics: Python (pandas, NumPy, scikit-learn, matplotlib, seaborn), SQL, Excel \\nMachine Learning & AI: Classification, Regression, NLP, Deep Learning, Feature Engineering, Model Evaluation \\nLLMs & Conversational AI: LangChain, RAG, Vector Databases (Pinecone, LanceDB), Prompt Engineering'}]\n",
      "* [Score=0.567] data into actionable insights and delivering production-ready ML solutions. Competitive ML participa... [{'source': 'cv', 'text': 'data into actionable insights and delivering production-ready ML solutions. Competitive ML participant (top \\n30% Zindi), passionate about solving high-impact problems with data. \\nSkills      \\nProgramming & Analytics: Python (pandas, NumPy, scikit-learn, matplotlib, seaborn), SQL, Excel'}]\n",
      "* [Score=0.533] Skills      \n",
      "Programming & Analytics: Python (pandas, NumPy, scikit-learn, matplotlib, seaborn), SQL... [{'source': 'cv', 'text': 'Skills      \\nProgramming & Analytics: Python (pandas, NumPy, scikit-learn, matplotlib, seaborn), SQL, Excel'}]\n"
     ]
    }
   ],
   "source": [
    "# Define a query\n",
    "query = \"what are the candidates skills relevant to data science?\"\n",
    "\n",
    "# Embed the query\n",
    "query_embedding = embedding_model.encode(query).tolist()\n",
    "\n",
    "# Query Pinecone\n",
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=3,  # Return top 3 results\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "# Print results\n",
    "for match in results[\"matches\"]:\n",
    "    print(f\"* [Score={match['score']:.3f}] {match['metadata']['text'][:100]}... [{match['metadata']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1c1d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
