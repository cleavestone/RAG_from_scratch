{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0b5b440",
   "metadata": {},
   "source": [
    "# ðŸ“„ Document Loaders in RAG\n",
    "\n",
    "This notebook explores **document loaders** â€” a crucial step in **Retrieval-Augmented Generation (RAG)** pipelines.\n",
    "\n",
    "Before embeddings and vector search, we need a way to **ingest raw data (PDFs, text, HTML, CSV, etc.) into structured document objects** that can be chunked and embedded.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Objectives\n",
    "- Understand the role of **document loaders** in RAG.  \n",
    "- Explore different **file types** that can be loaded.  \n",
    "- Learn how to use **LangChainâ€™s community loaders** for handling diverse data sources.  \n",
    "- Prepare documents for **chunking + embedding** in later steps.  \n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Topics Covered\n",
    "\n",
    "### 1. Introduction to Document Loaders\n",
    "- Why we need them in RAG pipelines  \n",
    "- Structure of a `Document` object (text + metadata)  \n",
    "\n",
    "### 2. PDF Loading Example\n",
    "- Using `PyPDFLoader` to load research papers and textbooks  \n",
    "- Inspecting how pages are stored as `Document` objects  \n",
    "\n",
    "### 3. Other Loader Options\n",
    "- **TextLoader** â†’ plain `.txt` files  \n",
    "- **CSVLoader** â†’ tabular data  \n",
    "- **UnstructuredFileLoader** â†’ general-purpose for HTML, Word, PowerPoint  \n",
    "- **WebBaseLoader** â†’ load directly from websites  \n",
    "\n",
    "### 4. Preparing for Chunking\n",
    "- Why we canâ€™t embed large documents directly  \n",
    "- Loader â†’ Chunker â†’ Embedder â†’ Retriever flow  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014677c5",
   "metadata": {},
   "source": [
    "### PDF Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d52a8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "# Loading documents - We shall load a pdf into a sequence of document objects\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path = \"resume.pdf\"\n",
    "loader = PyPDFLoader(file_path)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a43e29ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLEAVESTONE ADUNGO \n",
      "cleavestone94@gmail.com   |   +254703457427   |   Nairobi Kenya       \n",
      "GitHub: Link  |   Linkedln: Link | Portfolio: Link \n",
      "Summary      \n",
      "Data Scientist transitioning from finance with 2+ years of hands-on ML, NLP, and data analytics experience. \n",
      "Skilled in Python, SQL, statistical modeling, LLM fine-tuning, RAG systems, and MLOps pipelines. Diverse \n",
      "industry background (education, logistics, finance, data annotation) with a proven track record of turning raw \n",
      "data into action\n",
      "Education and Training      \n",
      "Moi University â€“ Eldoret, Kenya \n",
      "Bachelor of Science in Mathematics | 2012 â€“ 2017 \n",
      "Second Class Honors, Upper Division \n",
      "Relevant coursework: Probability & Statistics, Linear Algebra, Real Analysis, Numerical Methods, \n",
      "Mathematical Modeling, Calculus \n",
      "Projects      \n",
      "#HRJ#784bc4ba-1ee5-4196-8c02-14eda4a9e2f9# \n",
      "Customer Churn Prediction â€“ End-to-End MLOps Pipeline \n",
      "Built a production-ready churn prediction system for a banking dataset using LightGBM, achieving an ROC AU\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])  # First 500 characters of page 1\n",
    "print(docs[1].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c6be73",
   "metadata": {},
   "source": [
    "### CSV Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5b591cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='iris.csv',\n",
    "    csv_args={\n",
    "    'delimiter': ',',\n",
    "    'quotechar': '\"',\n",
    "    'fieldnames': ['ld', 'SepalLengthCm', 'SepalWidthCm','PetalLengthCm','PetalWidthCm','Species']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0371237b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ld: 1\n",
      "SepalLengthCm: 5.1\n",
      "SepalWidthCm: 3.5\n",
      "PetalLengthCm: 1.4\n",
      "PetalWidthCm: 0.2\n",
      "Species: Iris-setosa\n",
      "{'source': 'iris.csv', 'row': 1}\n"
     ]
    }
   ],
   "source": [
    "docs = loader.load()\n",
    "print(docs[1].page_content[:100])\n",
    "print(docs[1].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887190d3",
   "metadata": {},
   "source": [
    "## TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf65c995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded documents: 1\n",
      "Sample: # Complete RAG Course Outline: Beginner to Advanced\n",
      "\n",
      "## Module 1: Foundations and Prerequisites (Week 1-2)\n",
      "\n",
      "### 1.1 Introduction to RAG\n",
      "- What is Retrieval-Augmented Generation?\n",
      "- RAG vs Traditional Language Models\n",
      "- Key components of RAG systems\n",
      "- Use cases and applications\n",
      "- Industry examples and \n",
      "Number of chunks: 34\n",
      "First chunk:\n",
      " # Complete RAG Course Outline: Beginner to Advanced\n",
      "\n",
      "## Module 1: Foundations and Prerequisites (Week 1-2)\n",
      "\n",
      "### 1.1 Introduction to RAG\n",
      "- What is Retrieval-Augmented Generation?\n",
      "- RAG vs Traditional Language Models\n",
      "- Key components of RAG systems\n",
      "- Use cases and applications\n",
      "- Industry examples and success stories\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step 1: Load the text file\n",
    "loader = TextLoader(\"RAG_COURSE.txt\")  # replace with your file\n",
    "documents = loader.load()\n",
    "\n",
    "print(\"Loaded documents:\", len(documents))\n",
    "print(\"Sample:\", documents[0].page_content[:300])\n",
    "\n",
    "# Step 2: Split into chunks (important for RAG)\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,  # characters per chunk\n",
    "    chunk_overlap=100\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "print(\"Number of chunks:\", len(docs))\n",
    "print(\"First chunk:\\n\", docs[0].page_content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac252695",
   "metadata": {},
   "source": [
    "### WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9596246f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://en.wikipedia.org/wiki/Kenya', 'title': 'Kenya - Wikipedia', 'language': 'en'}\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Load a webpage directly\n",
    "url = \"https://en.wikipedia.org/wiki/Kenya\"\n",
    "loader = WebBaseLoader(url)\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "# Inspect the first document\n",
    "#print(docs[0].page_content[:500])   # Preview first 500 characters\n",
    "print(docs[0].metadata)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
